{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting MXNet models to ONNX\n",
    "\n",
    "In this tutorial, we will show how you can save MXNet models to ONNX format.\n",
    "ONNX exporter it a part of [MXNet repository](https://github.com/apache/incubator-mxnet/tree/master/python/mxnet/contrib/onnx/mx2onnx).\n",
    "\n",
    "Current MXNet-ONNX import and export operator support and coverage can be found [here](Operator support and coverage - https://cwiki.apache.org/confluence/display/MXNET/ONNX):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installations:\n",
    "First, install ONNX 1.2.1 version. Follow instructions on [ONNX repo](https://github.com/onnx/onnx).\n",
    "\n",
    "Make sure to install latest MXNet either from source or pip.\n",
    "\n",
    "```bash\n",
    "pip install mxnet --pre\n",
    "```\n",
    "\n",
    "* Note: ONNX exporter will be released as a part of MXNet v1.3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare MXNet model to convert to ONNX:\n",
    "\n",
    "Let's try out pretrained resnet model from [MXNet model zoo](http://data.mxnet.io/models/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet.contrib import onnx as onnx_mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet-18-0000.params', 'resnet-18-symbol.json', 'synset.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download pretrained resnet model - json and params from mxnet model zoo.\n",
    "path='http://data.mxnet.io/models/imagenet/'\n",
    "[mx.test_utils.download(path+'resnet/18-layers/resnet-18-0000.params'),\n",
    " mx.test_utils.download(path+'resnet/18-layers/resnet-18-symbol.json'),\n",
    " mx.test_utils.download(path+'synset.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Use MXNet to ONNX exporter:\n",
    "\n",
    "MXNet's ONNX \"export_model\" API accepts following inputs: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function export_model in module mxnet.contrib.onnx.mx2onnx.export_model:\n",
      "\n",
      "export_model(sym, params, input_shape, input_type=<type 'numpy.float32'>, onnx_file_path=u'model.onnx', verbose=False)\n",
      "    Exports the MXNet model file, passed as a parameter, into ONNX model.\n",
      "    Accepts both symbol,parameter objects as well as json and params filepaths as input.\n",
      "    Operator support and coverage - https://cwiki.apache.org/confluence/display/MXNET/ONNX\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    sym : str or symbol object\n",
      "        Path to the json file or Symbol object\n",
      "    params : str or symbol object\n",
      "        Path to the params file or params dictionary. (Including both arg_params and aux_params)\n",
      "    input_shape : List of tuple\n",
      "        Input shape of the model e.g [(1,3,224,224)]\n",
      "    input_type : data type\n",
      "        Input data type e.g. np.float32\n",
      "    onnx_file_path : str\n",
      "        Path where to save the generated onnx file\n",
      "    verbose : Boolean\n",
      "        If true will print logs of the model conversion\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    onnx_file_path : str\n",
      "        Onnx file path\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(onnx_mxnet.export_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the API description, you can see that `export_model` API accepts 2 kinds of inputs:\n",
    "\n",
    "### MXNet sym, params objects:\n",
    "\n",
    "    This is useful if you are training a model. At the end of training, you just need to invoke the `export_model` function and provide sym and params objects as inputs with other attributes to save the model in ONNX format.\n",
    "    \n",
    "### MXNet's exported json and params files:\n",
    "\n",
    "    This is useful if you have pretrained models and you want to convert them to ONNX format.\n",
    "\n",
    "In this tutorial, we will show second usecase: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloaded input symbol and params files\n",
    "sym = 'resnet-18-symbol.json'\n",
    "params = 'resnet-18-0000.params'\n",
    "# Standard Imagenet input - 3 channels, 224*224\n",
    "input_shape = (1,3,224,224)\n",
    "# Path of the output file\n",
    "onnx_file = 'mxnet_exported_resnet50.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Invoke export model API. It returns path of the converted onnx model\n",
    "converted_model_path = onnx_mxnet.export_model(sym, params, [input_shape], np.float32, onnx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mxnet_exported_resnet50.onnx\n"
     ]
    }
   ],
   "source": [
    "print(converted_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Check validity\n",
    "\n",
    "You can check validity of the converted ONNX model by using ONNX checker tool as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph mxnet_converted_model (\n",
      "  %data[FLOAT, 1x3x224x224]\n",
      ") initializers (\n",
      "  %bn_data_gamma[FLOAT, 3]\n",
      "  %bn_data_beta[FLOAT, 3]\n",
      "  %bn_data_moving_mean[FLOAT, 3]\n",
      "  %bn_data_moving_var[FLOAT, 3]\n",
      "  %conv0_weight[FLOAT, 64x3x7x7]\n",
      "  %bn0_gamma[FLOAT, 64]\n",
      "  %bn0_beta[FLOAT, 64]\n",
      "  %bn0_moving_mean[FLOAT, 64]\n",
      "  %bn0_moving_var[FLOAT, 64]\n",
      "  %stage1_unit1_bn1_gamma[FLOAT, 64]\n",
      "  %stage1_unit1_bn1_beta[FLOAT, 64]\n",
      "  %stage1_unit1_bn1_moving_mean[FLOAT, 64]\n",
      "  %stage1_unit1_bn1_moving_var[FLOAT, 64]\n",
      "  %stage1_unit1_conv1_weight[FLOAT, 64x64x3x3]\n",
      "  %stage1_unit1_bn2_gamma[FLOAT, 64]\n",
      "  %stage1_unit1_bn2_beta[FLOAT, 64]\n",
      "  %stage1_unit1_bn2_moving_mean[FLOAT, 64]\n",
      "  %stage1_unit1_bn2_moving_var[FLOAT, 64]\n",
      "  %stage1_unit1_conv2_weight[FLOAT, 64x64x3x3]\n",
      "  %stage1_unit1_sc_weight[FLOAT, 64x64x1x1]\n",
      "  %stage1_unit2_bn1_gamma[FLOAT, 64]\n",
      "  %stage1_unit2_bn1_beta[FLOAT, 64]\n",
      "  %stage1_unit2_bn1_moving_mean[FLOAT, 64]\n",
      "  %stage1_unit2_bn1_moving_var[FLOAT, 64]\n",
      "  %stage1_unit2_conv1_weight[FLOAT, 64x64x3x3]\n",
      "  %stage1_unit2_bn2_gamma[FLOAT, 64]\n",
      "  %stage1_unit2_bn2_beta[FLOAT, 64]\n",
      "  %stage1_unit2_bn2_moving_mean[FLOAT, 64]\n",
      "  %stage1_unit2_bn2_moving_var[FLOAT, 64]\n",
      "  %stage1_unit2_conv2_weight[FLOAT, 64x64x3x3]\n",
      "  %stage2_unit1_bn1_gamma[FLOAT, 64]\n",
      "  %stage2_unit1_bn1_beta[FLOAT, 64]\n",
      "  %stage2_unit1_bn1_moving_mean[FLOAT, 64]\n",
      "  %stage2_unit1_bn1_moving_var[FLOAT, 64]\n",
      "  %stage2_unit1_conv1_weight[FLOAT, 128x64x3x3]\n",
      "  %stage2_unit1_bn2_gamma[FLOAT, 128]\n",
      "  %stage2_unit1_bn2_beta[FLOAT, 128]\n",
      "  %stage2_unit1_bn2_moving_mean[FLOAT, 128]\n",
      "  %stage2_unit1_bn2_moving_var[FLOAT, 128]\n",
      "  %stage2_unit1_conv2_weight[FLOAT, 128x128x3x3]\n",
      "  %stage2_unit1_sc_weight[FLOAT, 128x64x1x1]\n",
      "  %stage2_unit2_bn1_gamma[FLOAT, 128]\n",
      "  %stage2_unit2_bn1_beta[FLOAT, 128]\n",
      "  %stage2_unit2_bn1_moving_mean[FLOAT, 128]\n",
      "  %stage2_unit2_bn1_moving_var[FLOAT, 128]\n",
      "  %stage2_unit2_conv1_weight[FLOAT, 128x128x3x3]\n",
      "  %stage2_unit2_bn2_gamma[FLOAT, 128]\n",
      "  %stage2_unit2_bn2_beta[FLOAT, 128]\n",
      "  %stage2_unit2_bn2_moving_mean[FLOAT, 128]\n",
      "  %stage2_unit2_bn2_moving_var[FLOAT, 128]\n",
      "  %stage2_unit2_conv2_weight[FLOAT, 128x128x3x3]\n",
      "  %stage3_unit1_bn1_gamma[FLOAT, 128]\n",
      "  %stage3_unit1_bn1_beta[FLOAT, 128]\n",
      "  %stage3_unit1_bn1_moving_mean[FLOAT, 128]\n",
      "  %stage3_unit1_bn1_moving_var[FLOAT, 128]\n",
      "  %stage3_unit1_conv1_weight[FLOAT, 256x128x3x3]\n",
      "  %stage3_unit1_bn2_gamma[FLOAT, 256]\n",
      "  %stage3_unit1_bn2_beta[FLOAT, 256]\n",
      "  %stage3_unit1_bn2_moving_mean[FLOAT, 256]\n",
      "  %stage3_unit1_bn2_moving_var[FLOAT, 256]\n",
      "  %stage3_unit1_conv2_weight[FLOAT, 256x256x3x3]\n",
      "  %stage3_unit1_sc_weight[FLOAT, 256x128x1x1]\n",
      "  %stage3_unit2_bn1_gamma[FLOAT, 256]\n",
      "  %stage3_unit2_bn1_beta[FLOAT, 256]\n",
      "  %stage3_unit2_bn1_moving_mean[FLOAT, 256]\n",
      "  %stage3_unit2_bn1_moving_var[FLOAT, 256]\n",
      "  %stage3_unit2_conv1_weight[FLOAT, 256x256x3x3]\n",
      "  %stage3_unit2_bn2_gamma[FLOAT, 256]\n",
      "  %stage3_unit2_bn2_beta[FLOAT, 256]\n",
      "  %stage3_unit2_bn2_moving_mean[FLOAT, 256]\n",
      "  %stage3_unit2_bn2_moving_var[FLOAT, 256]\n",
      "  %stage3_unit2_conv2_weight[FLOAT, 256x256x3x3]\n",
      "  %stage4_unit1_bn1_gamma[FLOAT, 256]\n",
      "  %stage4_unit1_bn1_beta[FLOAT, 256]\n",
      "  %stage4_unit1_bn1_moving_mean[FLOAT, 256]\n",
      "  %stage4_unit1_bn1_moving_var[FLOAT, 256]\n",
      "  %stage4_unit1_conv1_weight[FLOAT, 512x256x3x3]\n",
      "  %stage4_unit1_bn2_gamma[FLOAT, 512]\n",
      "  %stage4_unit1_bn2_beta[FLOAT, 512]\n",
      "  %stage4_unit1_bn2_moving_mean[FLOAT, 512]\n",
      "  %stage4_unit1_bn2_moving_var[FLOAT, 512]\n",
      "  %stage4_unit1_conv2_weight[FLOAT, 512x512x3x3]\n",
      "  %stage4_unit1_sc_weight[FLOAT, 512x256x1x1]\n",
      "  %stage4_unit2_bn1_gamma[FLOAT, 512]\n",
      "  %stage4_unit2_bn1_beta[FLOAT, 512]\n",
      "  %stage4_unit2_bn1_moving_mean[FLOAT, 512]\n",
      "  %stage4_unit2_bn1_moving_var[FLOAT, 512]\n",
      "  %stage4_unit2_conv1_weight[FLOAT, 512x512x3x3]\n",
      "  %stage4_unit2_bn2_gamma[FLOAT, 512]\n",
      "  %stage4_unit2_bn2_beta[FLOAT, 512]\n",
      "  %stage4_unit2_bn2_moving_mean[FLOAT, 512]\n",
      "  %stage4_unit2_bn2_moving_var[FLOAT, 512]\n",
      "  %stage4_unit2_conv2_weight[FLOAT, 512x512x3x3]\n",
      "  %bn1_gamma[FLOAT, 512]\n",
      "  %bn1_beta[FLOAT, 512]\n",
      "  %bn1_moving_mean[FLOAT, 512]\n",
      "  %bn1_moving_var[FLOAT, 512]\n",
      "  %fc1_weight[FLOAT, 1000x512]\n",
      "  %fc1_bias[FLOAT, 1000]\n",
      ") {\n",
      "  %bn_data = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%data, %bn_data_gamma, %bn_data_beta, %bn_data_moving_mean, %bn_data_moving_var)\n",
      "  %conv0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [2, 2]](%bn_data, %conv0_weight)\n",
      "  %bn0 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%conv0, %bn0_gamma, %bn0_beta, %bn0_moving_mean, %bn0_moving_var)\n",
      "  %relu0 = Relu(%bn0)\n",
      "  %pooling0 = MaxPool[kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%relu0)\n",
      "  %stage1_unit1_bn1 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%pooling0, %stage1_unit1_bn1_gamma, %stage1_unit1_bn1_beta, %stage1_unit1_bn1_moving_mean, %stage1_unit1_bn1_moving_var)\n",
      "  %stage1_unit1_relu1 = Relu(%stage1_unit1_bn1)\n",
      "  %stage1_unit1_conv1 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage1_unit1_relu1, %stage1_unit1_conv1_weight)\n",
      "  %stage1_unit1_bn2 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%stage1_unit1_conv1, %stage1_unit1_bn2_gamma, %stage1_unit1_bn2_beta, %stage1_unit1_bn2_moving_mean, %stage1_unit1_bn2_moving_var)\n",
      "  %stage1_unit1_relu2 = Relu(%stage1_unit1_bn2)\n",
      "  %stage1_unit1_conv2 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage1_unit1_relu2, %stage1_unit1_conv2_weight)\n",
      "  %stage1_unit1_sc = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%stage1_unit1_relu1, %stage1_unit1_sc_weight)\n",
      "  %_plus0 = Add(%stage1_unit1_conv2, %stage1_unit1_sc)\n",
      "  %stage1_unit2_bn1 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%_plus0, %stage1_unit2_bn1_gamma, %stage1_unit2_bn1_beta, %stage1_unit2_bn1_moving_mean, %stage1_unit2_bn1_moving_var)\n",
      "  %stage1_unit2_relu1 = Relu(%stage1_unit2_bn1)\n",
      "  %stage1_unit2_conv1 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage1_unit2_relu1, %stage1_unit2_conv1_weight)\n",
      "  %stage1_unit2_bn2 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%stage1_unit2_conv1, %stage1_unit2_bn2_gamma, %stage1_unit2_bn2_beta, %stage1_unit2_bn2_moving_mean, %stage1_unit2_bn2_moving_var)\n",
      "  %stage1_unit2_relu2 = Relu(%stage1_unit2_bn2)\n",
      "  %stage1_unit2_conv2 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage1_unit2_relu2, %stage1_unit2_conv2_weight)\n",
      "  %_plus1 = Add(%stage1_unit2_conv2, %_plus0)\n",
      "  %stage2_unit1_bn1 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%_plus1, %stage2_unit1_bn1_gamma, %stage2_unit1_bn1_beta, %stage2_unit1_bn1_moving_mean, %stage2_unit1_bn1_moving_var)\n",
      "  %stage2_unit1_relu1 = Relu(%stage2_unit1_bn1)\n",
      "  %stage2_unit1_conv1 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%stage2_unit1_relu1, %stage2_unit1_conv1_weight)\n",
      "  %stage2_unit1_bn2 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%stage2_unit1_conv1, %stage2_unit1_bn2_gamma, %stage2_unit1_bn2_beta, %stage2_unit1_bn2_moving_mean, %stage2_unit1_bn2_moving_var)\n",
      "  %stage2_unit1_relu2 = Relu(%stage2_unit1_bn2)\n",
      "  %stage2_unit1_conv2 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage2_unit1_relu2, %stage2_unit1_conv2_weight)\n",
      "  %stage2_unit1_sc = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%stage2_unit1_relu1, %stage2_unit1_sc_weight)\n",
      "  %_plus2 = Add(%stage2_unit1_conv2, %stage2_unit1_sc)\n",
      "  %stage2_unit2_bn1 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%_plus2, %stage2_unit2_bn1_gamma, %stage2_unit2_bn1_beta, %stage2_unit2_bn1_moving_mean, %stage2_unit2_bn1_moving_var)\n",
      "  %stage2_unit2_relu1 = Relu(%stage2_unit2_bn1)\n",
      "  %stage2_unit2_conv1 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage2_unit2_relu1, %stage2_unit2_conv1_weight)\n",
      "  %stage2_unit2_bn2 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%stage2_unit2_conv1, %stage2_unit2_bn2_gamma, %stage2_unit2_bn2_beta, %stage2_unit2_bn2_moving_mean, %stage2_unit2_bn2_moving_var)\n",
      "  %stage2_unit2_relu2 = Relu(%stage2_unit2_bn2)\n",
      "  %stage2_unit2_conv2 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage2_unit2_relu2, %stage2_unit2_conv2_weight)\n",
      "  %_plus3 = Add(%stage2_unit2_conv2, %_plus2)\n",
      "  %stage3_unit1_bn1 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%_plus3, %stage3_unit1_bn1_gamma, %stage3_unit1_bn1_beta, %stage3_unit1_bn1_moving_mean, %stage3_unit1_bn1_moving_var)\n",
      "  %stage3_unit1_relu1 = Relu(%stage3_unit1_bn1)\n",
      "  %stage3_unit1_conv1 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%stage3_unit1_relu1, %stage3_unit1_conv1_weight)\n",
      "  %stage3_unit1_bn2 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%stage3_unit1_conv1, %stage3_unit1_bn2_gamma, %stage3_unit1_bn2_beta, %stage3_unit1_bn2_moving_mean, %stage3_unit1_bn2_moving_var)\n",
      "  %stage3_unit1_relu2 = Relu(%stage3_unit1_bn2)\n",
      "  %stage3_unit1_conv2 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage3_unit1_relu2, %stage3_unit1_conv2_weight)\n",
      "  %stage3_unit1_sc = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%stage3_unit1_relu1, %stage3_unit1_sc_weight)\n",
      "  %_plus4 = Add(%stage3_unit1_conv2, %stage3_unit1_sc)\n",
      "  %stage3_unit2_bn1 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%_plus4, %stage3_unit2_bn1_gamma, %stage3_unit2_bn1_beta, %stage3_unit2_bn1_moving_mean, %stage3_unit2_bn1_moving_var)\n",
      "  %stage3_unit2_relu1 = Relu(%stage3_unit2_bn1)\n",
      "  %stage3_unit2_conv1 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage3_unit2_relu1, %stage3_unit2_conv1_weight)\n",
      "  %stage3_unit2_bn2 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%stage3_unit2_conv1, %stage3_unit2_bn2_gamma, %stage3_unit2_bn2_beta, %stage3_unit2_bn2_moving_mean, %stage3_unit2_bn2_moving_var)\n",
      "  %stage3_unit2_relu2 = Relu(%stage3_unit2_bn2)\n",
      "  %stage3_unit2_conv2 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage3_unit2_relu2, %stage3_unit2_conv2_weight)\n",
      "  %_plus5 = Add(%stage3_unit2_conv2, %_plus4)\n",
      "  %stage4_unit1_bn1 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%_plus5, %stage4_unit1_bn1_gamma, %stage4_unit1_bn1_beta, %stage4_unit1_bn1_moving_mean, %stage4_unit1_bn1_moving_var)\n",
      "  %stage4_unit1_relu1 = Relu(%stage4_unit1_bn1)\n",
      "  %stage4_unit1_conv1 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%stage4_unit1_relu1, %stage4_unit1_conv1_weight)\n",
      "  %stage4_unit1_bn2 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%stage4_unit1_conv1, %stage4_unit1_bn2_gamma, %stage4_unit1_bn2_beta, %stage4_unit1_bn2_moving_mean, %stage4_unit1_bn2_moving_var)\n",
      "  %stage4_unit1_relu2 = Relu(%stage4_unit1_bn2)\n",
      "  %stage4_unit1_conv2 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage4_unit1_relu2, %stage4_unit1_conv2_weight)\n",
      "  %stage4_unit1_sc = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%stage4_unit1_relu1, %stage4_unit1_sc_weight)\n",
      "  %_plus6 = Add(%stage4_unit1_conv2, %stage4_unit1_sc)\n",
      "  %stage4_unit2_bn1 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%_plus6, %stage4_unit2_bn1_gamma, %stage4_unit2_bn1_beta, %stage4_unit2_bn1_moving_mean, %stage4_unit2_bn1_moving_var)\n",
      "  %stage4_unit2_relu1 = Relu(%stage4_unit2_bn1)\n",
      "  %stage4_unit2_conv1 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage4_unit2_relu1, %stage4_unit2_conv1_weight)\n",
      "  %stage4_unit2_bn2 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%stage4_unit2_conv1, %stage4_unit2_bn2_gamma, %stage4_unit2_bn2_beta, %stage4_unit2_bn2_moving_mean, %stage4_unit2_bn2_moving_var)\n",
      "  %stage4_unit2_relu2 = Relu(%stage4_unit2_bn2)\n",
      "  %stage4_unit2_conv2 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%stage4_unit2_relu2, %stage4_unit2_conv2_weight)\n",
      "  %_plus7 = Add(%stage4_unit2_conv2, %_plus6)\n",
      "  %bn1 = BatchNormalization[epsilon = 1.99999994947575e-05, momentum = 0.899999976158142, spatial = 0](%_plus7, %bn1_gamma, %bn1_beta, %bn1_moving_mean, %bn1_moving_var)\n",
      "  %relu1 = Relu(%bn1)\n",
      "  %pool1 = GlobalAveragePool(%relu1)\n",
      "  %flatten0 = Flatten(%pool1)\n",
      "  %fc1 = Gemm[alpha = 1, beta = 1, transA = 0, transB = 1](%flatten0, %fc1_weight, %fc1_bias)\n",
      "  %softmax = Softmax[axis = 1](%fc1)\n",
      "  return %softmax\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from onnx import checker\n",
    "import onnx\n",
    "# Load onnx model\n",
    "model_proto = onnx.load(converted_model_path)\n",
    "\n",
    "# Check if converted ONNX protobuf is valid\n",
    "checker.check_graph(model_proto.graph)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model_proto.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next\n",
    "\n",
    "Take a look at [other tutorials, including importing of ONNX models to other frameworks](https://github.com/onnx/tutorials/tree/master/tutorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx_mxnet",
   "language": "python",
   "name": "onnx_mxnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
